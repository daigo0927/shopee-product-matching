datadir: 'data'

preprocess:
  target_size: [256, 256]
  tokenizer:
    type: ${model.bert_weights}
    max_length: 128
  tfidf:
    stop_words: 'english'
    binary: True
    max_features: 25000
  encoder_weights: 'assets/universal-sentence-encoders/universal-sentence-encoder-multilingual_3'

model:
  image_size: ${preprocess.target_size}
  token_length: ${preprocess.tokenizer.max_length}
  tfidf_dim: ${preprocess.tfidf.max_features}
  final_feature_dim: 1024
  effnet_type: 'EfficientNetB0'
  effnet_weights: 'assets/effnet_official/noisy_student_efficientnet-b0_notop.h5'
  bert_weights: 'assets/bert-weights-basic/distilbert-base-cased'
  circle_loss:
    margin: 0.25
    scale: 256

train:
  n_splits: 5
  epochs: 25
  batch_size: 16
  learning_rate: 0.001
  checkpoint:
    save_step: 5

logdir: 'outputs'
